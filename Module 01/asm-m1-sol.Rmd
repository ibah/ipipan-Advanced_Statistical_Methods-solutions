---
title: "ASM - Module 1 Exercises"
author: "Michal Siwek"
date: "Monday, October 12, 2015"
output: pdf_document
---

## Task 1
Data:
```{r}
p_red <- c(2/3, 1/2, 1/3)
p_green <- 1 - p_red
all_lights <- 1:3
```
Calculating the distribution $F_X(x)$. For every $x \in (0, 1, 2, 3)$:

1. find all elementary events that have $x$ red lights
2. calculate the probability of each of those elementary events
3. sum up the probabilities and assign to $x$
```{r}
FX <- sapply(0:3, function(x) {
    elem_events <- combn(all_lights, x)
    p_elem_events <- apply(elem_events, 2, function(red_lights) {
            green_lights <- setdiff(all_lights, red_lights)
            prod(p_red[red_lights], p_green[green_lights])
        })
    c(x, sum(p_elem_events))
})
rownames(FX) <- c("x", "F(x)")
FX
```
## Task 2
Data:
```{r}
mn <- 100
sd <- 15
```
a) Probability that $x > 130$
```{r}
pnorm(130, mean = mn, sd = sd, lower.tail = F)
```
b) Probability that $x \in [100, 120]$
```{r}
pnorm(120, mean = mn, sd = sd) - pnorm(100, mean = mn, sd = sd)
```
## Task 3
Data:
```{r}
pxy <- matrix(
        c(c(.1, .1, 0),
          c(.2, .2, .1),
          c(.1, .1, .1)),
        nrow = 3,
        byrow = T,
        dimnames = list(X=c(0, 1, 2), Y=c(-1, 0, 1))
    )
pxy
```
a) Marginal distribution $p_x$ for $X$:
```{r}
px <- apply(pxy, 1, sum)
x <- as.numeric(names(px))
px
```
Marginal distribution $p_y$ for $Y$:
```{r}
py <- apply(pxy, 2, sum)
y <- as.numeric(names(py))
py
```
b) Calculating $P(X > 2Y)$:
```{r}
cond <- matrix(nrow = 3, ncol = 3)
for(i in seq_len(nrow(pxy)))
    for(j in seq_len(ncol(pxy)))
        cond[i,j] <- as.numeric(rownames(pxy)[i]) > 2 * as.numeric(colnames(pxy)[j])
sum(pxy[cond])
```
c) Calculating covariance of $X$ and $Y$:
```{r}
mn_x <- sum(x * px)
mn_y <- sum(y * py)
tmp <- matrix(nrow = 3, ncol = 3)
for(i in seq_len(nrow(pxy)))
    for(j in seq_len(ncol(pxy)))
        tmp[i, j] <- pxy[i,j] * (x[i] - mn_x) * (y[j] - mn_y)
cov_xy <- sum(tmp)
cov_xy
# different method:
exp_xy <- sum(
    outer(1:nrow(pxy), 1:ncol(pxy),
          Vectorize(
              function(r, c) x[r] * y[c] * pxy[r, c]
          )))
exp_x <- sum(x * px)
exp_y <- sum(y * py)
exp_xy - exp_x * exp_y  # the same result as when calc. from the definition
```
Calculating correlation of $X$ and $Y$:
```{r}
var_x <- sum(px * (x - mn_x)^2)
var_y <- sum(py * (y - mn_y)^2)
cor_xy <- cov_xy/sqrt(var_x * var_y)
cor_xy
```
The variables aren't independent as covariance and correlation are both different than $0$.
WRONG: The frequency table for the joint distribution of $X$ and $Y$ should be filled with equal values (i.e. $1/9$ here) for $X$ and $Y$ to be independent.
Maybe: it's enought for the table to be symmetric - but how symmetric?
Correct: X and Y are independent if the table = tables of the outer product of marginal probabilities of X and Y.

d) Conditional distribution of $X$ given $Y = -1$:
```{r}
FX_y <- sapply(pxy[, 1], function(p) p / sum(pxy[, 1]))
FX_y
```
Conditional distribution of $Y$ given $X = 0$:
```{r}
FY_x <- sapply(pxy[1, ], function(p) p / sum(pxy[1, ]))
FY_x
```
## Task 4
Data:
```{r}
x_min <- 1.4
x_max <- 1.8
f_x <- 1 / (x_max - x_min)
```
Deriving population mean and standard deviation from the definitions for continuous distributions:
```{r}
mn_x <- 2.5 * x_max^2 / 2 - 2.5 * x_min^2 / 2
E_of_squared_x <- 2.5 * x_max^3 / 3 - 2.5 * x_min^3 / 3
var_x <- E_of_squared_x - (mn_x)^2
sd_x <- sqrt(var_x)
```
We use CLT for sums of random variables to find the mean and standartd deviation for the sum of 50 randoms:
```{r}
n <- 50
mn <- n * mn_x
sd <- sqrt(n) * sd_x
mn
sd
n * var_x  # variance of the sum
```
According to CLT, our random variable (approximate time of 50km cycling) has approximately normal distribution
with the mean `r mn` and standard deviation `r sd`.

## Task 5
Data:
```{r}
n <- 50
mn <- 28.40
sd <- 4.75
```
The confidence interval for population mean using CLT:
```{r}
mn + c(-1, 1) * qnorm(.975) * sd / sqrt(n)
```
## Task 6
Data:
```{r}
n <- 400
rec <- 79
```
Two sided test, at $\alpha = 5\%$:

* $H_0 : \mu = 25\%$
* $H_1 : \mu \neq 25\%$

Assuming the distribution is binomial we can derive standard deviation form the mu.
```{r}
mu0 <- .25
mn <- rec / n
var0 <- mu0 * (1 - mu0) / n
```
Test statistic and p-value:
```{r}
t.stat <- (mn - mu0) / sqrt(var0)
2 * pnorm(t.stat)
```
$H_0$ is rejected as the p-value is below $5\%$.

## Task 7
Data:
```{r}
mu0 <- 3.2
n <- 50
mn <- 3.05
se <- 0.34
```
Test statistic and the p-value:
```{r}
t.stat <- sqrt(n) * (mn - mu0) / se
pt(t.stat, n - 1)
```
$H_0$ rejected as p-value is lower than $5\%$.
